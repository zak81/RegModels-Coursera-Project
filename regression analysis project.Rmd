---
title: "Regression Analysis on MPG and Transmission"
author: "Yosuke Ishizaka"
output: pdf_document
---
##Executive Summary:
The goal of this project is to answer some questions using regression models and exploratory data analyses.  We are particularly interested in answering the following questions:

* Is an automatic or manual transmission better for MPG?

* Quantify the MPG difference between automatic and manual transmissions.

In this analysis, we've determined that manual transmission achieves higher MPG.

##Exploratory Data Analyses:
Consider the `mtcars` data set.  We'll start by looking at dimensions and variable names.
```{r, echo=FALSE}
data(mtcars)
dim(mtcars)
names(mtcars)
```
Look at the first 6 rows of data set.
```{r, echo=FALSE}
head(mtcars)
```
There exists 32 rows of car models with 11 variables.  We'll fit a linear model with MPG as the outcome and all remaining variables as predictive variables.
```{r, echo=FALSE}
summary(lm(mpg~.-1, data=mtcars))$coef
```
Fitting a model with 10 predictors results in no significant P-values (less than 0.05).  We eliminate predictors to determine a model with better fit.  After eliminating predictors from the order of high P-values, we end up with a model with wt, qsec and am as significant predictors.  Here are the coefficient estimates and R-squared.
```{r, echo=FALSE}
fit <- lm(mpg~wt+qsec+factor(am)-1, data=mtcars)
summary(fit)$coef
summary(fit)$r.squared
```
Usint this model to answer the first question, "Is an automatic or manual transmission better for MPG?", compare the coefficients of `factor(am)`. Factor(am)=1 for manual transmission is 2.936 mpg more efficient than automatic transmission.  Clearly, manual transmission is better for MPG.
To determine if I should include any interaction term, I check for correlation between transmission and each predictors.
```{r, echo=FALSE}
cor(mtcars["am"], mtcars[c("wt", "qsec")])
```
Weight (wt) has -0.69 correlation to Transmission (am).  This means that there is a negative correlation, so I include the interaction term `am*wt`.  
1/4 mile time (qsec) does not show a correlation.
Here are the coefficient estimates and R-squared.
```{r, echo=FALSE}
fit <- lm(mpg~wt+qsec+factor(am)+wt*factor(am)-1, data=mtcars)
summary(fit)$coef
summary(fit)$r.squared
```
Inclusion of interaction term `wt*am` changes the interpretation.  For `am=0`, model is `9.72 - 2.94wt + 1.02qsec`.  For `am=1`, model is `-2.94wt + 1.017qsec + (23.80 - 4.14wt)*am`.  Since `am=1` is interacted with wt, change in mpg is also dependent on wt in the term `(23.80 - 4.14wt)*am`.  Other variables weight decreases mpg by 2.94 and 1/4 mile time increases mpg by 1.02.

We can look at the uncertainty in parameters.  We have 95% confidence that parameters are within each interval.
```{r, echo=FALSE}
confint(fit)
```

##Residuals Diagnostics:
Residuals should be uncorrelated with the fit and independent and nearly identically distributed with mean zero.  We'll look at the plot of residuals against fitted values.  We see a few outliers that may be influential.    (Appendix: Figure 1)

```{r, figure1, echo=FALSE, fig.show='hide'}
plot(fit, which=1)
```

We'll look at the Q-Q plot next.  We see that residuals are along the line of normality.  Notice we have the same outliers as the previous plot.  (Appendix: Figure 2)

```{r, figure2, echo=FALSE, fig.show='hide'}
plot(fit, which=2)
```

Next, we find influence of the outliers on coefficients.  Outliers are Datsun 710, Fiat 128 and Mercedes 240D.  Influence on coefficients are higher for the outliers, but not dramatically high.  My decision is to leave the outliers in the model because looking also at the plots, they do not seem to influence the normality and correlation within the fit.
```{r, echo=FALSE}
round(dfbetas(fit)[c("Datsun 710", "Fiat 128", "Merc 240D"),], 3)
head(round(dfbetas(fit), 3), 2)
```
\pagebreak

##Appendix:

Figure 1
```{r, figure1, fig.width=8, fig.height=4, echo=FALSE}
```

Figure2
```{r, figure2, fig.width=8, fig.height=4, echo=FALSE}
```
